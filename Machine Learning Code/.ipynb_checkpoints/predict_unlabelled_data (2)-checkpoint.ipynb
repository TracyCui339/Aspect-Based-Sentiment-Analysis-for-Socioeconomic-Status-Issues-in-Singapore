{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37109,
     "status": "ok",
     "timestamp": 1682225065334,
     "user": {
      "displayName": "Tracy Cui",
      "userId": "16412396047916717499"
     },
     "user_tz": -480
    },
    "id": "WigMaOD6jrzw",
    "outputId": "9b759ce1-cc9f-4a81-e93c-5b05f933f988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12035,
     "status": "ok",
     "timestamp": 1682225136469,
     "user": {
      "displayName": "Tracy Cui",
      "userId": "16412396047916717499"
     },
     "user_tz": -480
    },
    "id": "G3TKvH_E1sL_",
    "outputId": "a6a1108d-b58e-4068-91ea-6e413217f083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1682186874024,
     "user": {
      "displayName": "Tracy Cui",
      "userId": "16412396047916717499"
     },
     "user_tz": -480
    },
    "id": "EzRQukrJJp-F",
    "outputId": "ee3dfa22-c129-41d1-c515-3dd648d585c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")         \n",
    "    print('GPU is available')\n",
    "else:\n",
    "    device = torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1682225183378,
     "user": {
      "displayName": "Tracy Cui",
      "userId": "16412396047916717499"
     },
     "user_tz": -480
    },
    "id": "KRRo-tOe1_29"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Machine Learning Code2/Machine Learning Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14970,
     "status": "ok",
     "timestamp": 1682225200080,
     "user": {
      "displayName": "Tracy Cui",
      "userId": "16412396047916717499"
     },
     "user_tz": -480
    },
    "id": "SIDkgqj61od_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import build_tokenizer, build_embedding_matrix, Tokenizer4Bert, pad_and_truncate\n",
    "from models import LSTM, IAN, MemNet, RAM, TD_LSTM, TC_LSTM, Cabasc, ATAE_LSTM, TNet_LF, AOA, MGAN, ASGCN, LCF_BERT\n",
    "from models.aen import CrossEntropyLoss_LSR, AEN_BERT\n",
    "from models.bert_spc import BERT_SPC\n",
    "#from dependency_graph import dependency_adj_matrix\n",
    "\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1682225223627,
     "user": {
      "displayName": "Tracy Cui",
      "userId": "16412396047916717499"
     },
     "user_tz": -480
    },
    "id": "CzOl5xJtjrzz"
   },
   "outputs": [],
   "source": [
    "class Inferer:\n",
    "    \"\"\"A simple inference example\"\"\"\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        if 'bert' in opt.model_name:\n",
    "            self.tokenizer = Tokenizer4Bert(opt.max_seq_len, opt.pretrained_bert_name)\n",
    "            bert = BertModel.from_pretrained(opt.pretrained_bert_name, return_dict=False)\n",
    "            self.model = opt.model_class(bert, opt).to(opt.device)\n",
    "        else:\n",
    "            self.tokenizer = build_tokenizer(\n",
    "                fnames=[opt.dataset_file['train'], opt.dataset_file['test']],\n",
    "                max_seq_len=opt.max_seq_len,\n",
    "                dat_fname='{0}_tokenizer.dat'.format(opt.dataset))\n",
    "            embedding_matrix = build_embedding_matrix(\n",
    "                word2idx=self.tokenizer.word2idx,\n",
    "                embed_dim=opt.embed_dim,\n",
    "                dat_fname='{0}_{1}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset))\n",
    "            self.model = opt.model_class(embedding_matrix, opt)\n",
    "        print('loading model {0} ...'.format(opt.model_name))\n",
    "        self.model.load_state_dict(torch.load(opt.state_dict_path))\n",
    "        self.model = self.model.to(opt.device)\n",
    "        # switch model to evaluation mode\n",
    "        self.model.eval()\n",
    "        torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "    def evaluate(self, text, aspect):\n",
    "        aspect = aspect.lower().strip()\n",
    "        text_left, _, text_right = [s.strip() for s in text.lower().partition(aspect)]\n",
    "        \n",
    "        text_indices = self.tokenizer.text_to_sequence(text_left + \" \" + aspect + \" \" + text_right)\n",
    "        context_indices = self.tokenizer.text_to_sequence(text_left + \" \" + text_right)\n",
    "        left_indices = self.tokenizer.text_to_sequence(text_left)\n",
    "        left_with_aspect_indices = self.tokenizer.text_to_sequence(text_left + \" \" + aspect)\n",
    "        right_indices = self.tokenizer.text_to_sequence(text_right, reverse=True)\n",
    "        right_with_aspect_indices = self.tokenizer.text_to_sequence(aspect + \" \" + text_right, reverse=True)\n",
    "        aspect_indices = self.tokenizer.text_to_sequence(aspect)\n",
    "        left_len = np.sum(left_indices != 0)\n",
    "        aspect_len = np.sum(aspect_indices != 0)\n",
    "        aspect_boundary = np.asarray([left_len, left_len + aspect_len - 1], dtype=np.int64)\n",
    "\n",
    "        text_len = np.sum(text_indices != 0)\n",
    "        concat_bert_indices = self.tokenizer.text_to_sequence('[CLS] ' + text_left + \" \" + aspect + \" \" + text_right + ' [SEP] ' + aspect + \" [SEP]\")\n",
    "        concat_segments_indices = [0] * (text_len + 2) + [1] * (aspect_len + 1)\n",
    "        concat_segments_indices = pad_and_truncate(concat_segments_indices, self.tokenizer.max_seq_len)\n",
    "\n",
    "        text_bert_indices = self.tokenizer.text_to_sequence(\"[CLS] \" + text_left + \" \" + aspect + \" \" + text_right + \" [SEP]\")\n",
    "        aspect_bert_indices = self.tokenizer.text_to_sequence(\"[CLS] \" + aspect + \" [SEP]\")\n",
    "\n",
    "        #dependency_graph = dependency_adj_matrix(text)\n",
    "\n",
    "        data = {\n",
    "            'concat_bert_indices': concat_bert_indices,\n",
    "            'concat_segments_indices': concat_segments_indices,\n",
    "            'text_bert_indices': text_bert_indices,\n",
    "            'aspect_bert_indices': aspect_bert_indices,\n",
    "            'text_indices': text_indices,\n",
    "            'context_indices': context_indices,\n",
    "            'left_indices': left_indices,\n",
    "            'left_with_aspect_indices': left_with_aspect_indices,\n",
    "            'right_indices': right_indices,\n",
    "            'right_with_aspect_indices': right_with_aspect_indices,\n",
    "            'aspect_indices': aspect_indices,\n",
    "            'aspect_boundary': aspect_boundary,\n",
    "            #'dependency_graph': dependency_graph,\n",
    "        }\n",
    "\n",
    "        t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
    "        t_outputs = self.model(t_inputs)\n",
    "        t_probs = F.softmax(t_outputs, dim=-1).cpu().numpy()\n",
    "\n",
    "        return t_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4094,
     "status": "ok",
     "timestamp": 1682187124934,
     "user": {
      "displayName": "Tracy Cui",
      "userId": "16412396047916717499"
     },
     "user_tz": -480
    },
    "id": "GXJIo-h3jrz0",
    "outputId": "545866a4-aa03-440e-d3d1-32eb2d365961"
   },
   "outputs": [],
   "source": [
    "    model_classes = {\n",
    "        'lstm': LSTM,\n",
    "        'td_lstm': TD_LSTM,\n",
    "        'tc_lstm': TC_LSTM,\n",
    "        'atae_lstm': ATAE_LSTM,\n",
    "        'ian': IAN,\n",
    "        'memnet': MemNet,\n",
    "        'ram': RAM,\n",
    "        'cabasc': Cabasc,\n",
    "        'tnet_lf': TNet_LF,\n",
    "       'aoa': AOA,\n",
    "        'mgan': MGAN,\n",
    "        'asgcn': ASGCN,\n",
    "        'bert_spc': BERT_SPC,\n",
    "        'aen_bert': AEN_BERT,\n",
    "        'lcf_bert': LCF_BERT,\n",
    "    }\n",
    "    dataset_files = {\n",
    "        'twitter': {\n",
    "            'train': './datasets/acl-14-short-data/train.raw',\n",
    "            'test': './datasets/acl-14-short-data/test.raw'\n",
    "        },\n",
    "        'restaurant': {\n",
    "            'train': './datasets/semeval14/traindata2.xml.seg',\n",
    "            'test': './datasets/semeval14/testdata2.xml.seg'\n",
    "        },\n",
    "        'laptop': {\n",
    "            'train': './datasets/semeval14/Laptops_Train.xml.seg',\n",
    "            'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'\n",
    "        }\n",
    "    }\n",
    "    input_colses = {\n",
    "        'lstm': ['text_indices'],\n",
    "        'td_lstm': ['left_with_aspect_indices', 'right_with_aspect_indices'],\n",
    "        'tc_lstm': ['left_with_aspect_indices', 'right_with_aspect_indices', 'aspect_indices'],\n",
    "        'atae_lstm': ['text_indices', 'aspect_indices'],\n",
    "        'ian': ['text_indices', 'aspect_indices'],\n",
    "        'memnet': ['context_indices', 'aspect_indices'],\n",
    "        'ram': ['text_indices', 'aspect_indices', 'left_indices'],\n",
    "        'cabasc': ['text_indices', 'aspect_indices', 'left_with_aspect_indices', 'right_with_aspect_indices'],\n",
    "        'tnet_lf': ['text_indices', 'aspect_indices', 'aspect_in_text'],\n",
    "        'aoa': ['text_indices', 'aspect_indices'],\n",
    "        'mgan': ['text_indices', 'aspect_indices', 'left_indices'],\n",
    "        'asgcn': ['text_indices', 'aspect_indices', 'left_indices', 'dependency_graph'],\n",
    "        'bert_spc': ['concat_bert_indices', 'concat_segments_indices'],\n",
    "        'aen_bert': ['text_bert_indices', 'aspect_bert_indices'],\n",
    "        'lcf_bert': ['concat_bert_indices', 'concat_segments_indices', 'text_bert_indices', 'aspect_bert_indices'],\n",
    "    }\n",
    "    class Option(object): pass\n",
    "    opt = Option()\n",
    "    opt.model_name = 'lcf_bert'\n",
    "    opt.model_class = model_classes[opt.model_name]\n",
    "    opt.dataset = 'restaurant'\n",
    "    opt.dataset_file = dataset_files[opt.dataset]\n",
    "    opt.inputs_cols = input_colses[opt.model_name]\n",
    "    # set your trained models here\n",
    "    opt.state_dict_path = './state_dict/model_file_others'\n",
    "    opt.embed_dim = 768\n",
    "    opt.hidden_dim = 768\n",
    "    opt.max_seq_len = 200\n",
    "    opt.bert_dim = 768\n",
    "    opt.pretrained_bert_name = 'bert-base-uncased'\n",
    "    opt.polarities_dim = 3\n",
    "    opt.hops = 3\n",
    "    #torch.cuda.set_device(7)\n",
    "    #opt.device = torch.device('cuda:')\n",
    "    CUDA_VISIBLE_DEVICES=3\n",
    "    opt.device = torch.cuda.set_device(\"cuda:0\")\n",
    "    \n",
    "    print(opt.device)\n",
    "    #opt.device = torch.device('cpu')\n",
    "    opt.local_context_focus = 'cdw'\n",
    "    opt.SRD = 128\n",
    "    opt.dropout = 0\n",
    "  \n",
    "\n",
    "    inf = Inferer(opt)\n",
    "    t_probs = inf.evaluate('the service is excellent but the food is horrible', 'service')\n",
    "    print(t_probs.argmax(axis=-1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWhJOWW9jrz2"
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "3H-ylwsgjrz3",
    "outputId": "3259ecf6-8b56-475d-bb9c-3334ecc399db"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To use previous trained model to predict more unlabelled data\n",
    "\"\"\"\n",
    "\n",
    "input = pd.read_csv('./datasets/predictshort.csv')\n",
    "\n",
    "sentence = input['Target_Sentence']\n",
    "term = input['Search_Term']\n",
    "input['predicted_polarity'] = \"\"\n",
    "a = input['predicted_polarity']\n",
    "\n",
    "length_data =len(input)\n",
    "for i in range(length_data):\n",
    "   t_probs = inf.evaluate(sentence[i], term[i])\n",
    "   a[i] = (t_probs.argmax(axis=-1)-1)\n",
    "\n",
    "input['predicted_polarity'] = a.str.get(0)\n",
    "\n",
    "##to export all predicted sentiment polarities\n",
    "input.to_csv('./datasets/predictdata_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R05WM-kpjrz3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
